{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fb7df4",
   "metadata": {},
   "source": [
    "<h2> Imports, loading event-log function and cleaning pipeline </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "819e851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import statistics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a09798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset from file path\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    return pm4py.convert_to_dataframe(log)\n",
    "\n",
    "# Cleaning dataset: removing unnecessary columns, shifting to resource focus\n",
    "def clean_dataset(df):\n",
    "    df_final = df[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "    return df_final.sort_values(by=['org:resource', 'time:timestamp'])\n",
    "\n",
    "def prefix_extraction(df, min_len=1, max_len=None):\n",
    "    \"\"\"\n",
    "    Extract prefixes per resource.\n",
    "    \"\"\"\n",
    "    resource_traces = df.groupby('org:resource')['concept:name'].apply(list)\n",
    "    all_rows = []\n",
    "\n",
    "    for resource, seq in resource_traces.items():\n",
    "        max_prefix_len = len(seq) if max_len is None else min(max_len, len(seq))\n",
    "\n",
    "        for k in range(min_len, max_prefix_len):\n",
    "            prefix = seq[:k]\n",
    "            next_act = seq[k] if k < len(seq) else None\n",
    "\n",
    "            all_rows.append({\n",
    "                'resource': resource,\n",
    "                'prefix': prefix,\n",
    "                'prefix_length': k,\n",
    "                'last_activity': prefix[-1] if len(prefix) else None,\n",
    "                'next_activity': next_act\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(all_rows)\n",
    "\n",
    "def apply_bucketing(df):\n",
    "    df = df.copy()\n",
    "    df['bucket_key'] = df.apply(\n",
    "        lambda row: (row['prefix_length'], row['last_activity']), axis=1\n",
    "    )\n",
    "    df['bucket_id'] = df['bucket_key'].apply(lambda k: abs(hash(k)) % 10_000_000)\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_dataset(file_path):\n",
    "    df = import_xes(file_path)\n",
    "    df_clean = clean_dataset(df)\n",
    "    df_prefix = prefix_extraction(df_clean)\n",
    "    df_final = apply_bucketing(df_prefix)\n",
    "    return df_final \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07556d6f",
   "metadata": {},
   "source": [
    "<h1> Loading event-logs and transforming</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9d87f",
   "metadata": {},
   "source": [
    "<h4> Loading datasets </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0e27c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 7554/7554 [00:02<00:00, 3214.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully loaded 2013 dataset\n"
     ]
    }
   ],
   "source": [
    "df_2013 = process_dataset(\"datasets/BPI_Challenge_2013_incidents.xes\")\n",
    "print(\"Sucessfully loaded 2013 dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551418da",
   "metadata": {},
   "source": [
    "<h1>One-Hot Encoding the event-logs</h1>\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b687e",
   "metadata": {},
   "source": [
    "<h4> Apply One-Hot encoding function </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deb7b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_one_hot_encoding(df):\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    for col in ['last_activity', 'resource', 'next_activity']:\n",
    "        dummies = pd.get_dummies(df_encoded[col], prefix=col)\n",
    "        df_encoded = pd.concat([df_encoded.drop(col, axis=1), dummies], axis=1)\n",
    "\n",
    "    df_encoded = df_encoded.drop(columns=['prefix'], errors='ignore')\n",
    "    df_encoded = df_encoded.drop(columns=['bucket_key'], errors='ignore')\n",
    "\n",
    "    return df_encoded\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd6c4b",
   "metadata": {},
   "source": [
    "<h4> OHE the BPIC 2013 event-log </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4914b184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prefix_length  bucket_id  last_activity_Accepted  last_activity_Completed  \\\n",
      "0              1    9460431                    True                    False   \n",
      "1              2     559493                    True                    False   \n",
      "2              3    4681928                    True                    False   \n",
      "3              4    4701852                    True                    False   \n",
      "4              5    2904627                    True                    False   \n",
      "\n",
      "   last_activity_Queued  last_activity_Unmatched  resource_-  resource_Aaron  \\\n",
      "0                 False                    False        True           False   \n",
      "1                 False                    False        True           False   \n",
      "2                 False                    False        True           False   \n",
      "3                 False                    False        True           False   \n",
      "4                 False                    False        True           False   \n",
      "\n",
      "   resource_Abby  resource_Abdul  ...  resource_Zelda  resource_Zoi  \\\n",
      "0          False           False  ...           False         False   \n",
      "1          False           False  ...           False         False   \n",
      "2          False           False  ...           False         False   \n",
      "3          False           False  ...           False         False   \n",
      "4          False           False  ...           False         False   \n",
      "\n",
      "   resource_yoshiyuki  resource_Åke  resource_Åsa  resource_Åse  \\\n",
      "0               False         False         False         False   \n",
      "1               False         False         False         False   \n",
      "2               False         False         False         False   \n",
      "3               False         False         False         False   \n",
      "4               False         False         False         False   \n",
      "\n",
      "   next_activity_Accepted  next_activity_Completed  next_activity_Queued  \\\n",
      "0                    True                    False                 False   \n",
      "1                    True                    False                 False   \n",
      "2                    True                    False                 False   \n",
      "3                    True                    False                 False   \n",
      "4                    True                    False                 False   \n",
      "\n",
      "   next_activity_Unmatched  \n",
      "0                    False  \n",
      "1                    False  \n",
      "2                    False  \n",
      "3                    False  \n",
      "4                    False  \n",
      "\n",
      "[5 rows x 1292 columns]\n"
     ]
    }
   ],
   "source": [
    "df_2013_onehot = apply_one_hot_encoding(df_2013)\n",
    "print(df_2013_onehot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5167474",
   "metadata": {},
   "source": [
    "<h1> Training Random Forest model on OHE event-logs </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad50b67",
   "metadata": {},
   "source": [
    "<h4> Random Forest Training Pipeline </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58fe3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_pipeline(df):\n",
    "    # Remove rows with no next activity (end of resource trace)\n",
    "    target_columns = [c for c in df.columns if c.startswith(\"next_activity_\")]\n",
    "    df_model = df[df[target_columns].sum(axis=1) > 0]\n",
    "\n",
    "    feature_columns = [\n",
    "        col for col in df_model.columns \n",
    "        if col.startswith(\"last_activity_\")\n",
    "        or col.startswith(\"resource_\")\n",
    "        or col == \"prefix_length\"\n",
    "        or col == \"bucket_id\"\n",
    "    ]\n",
    "\n",
    "    target_columns = [c for c in df_model.columns if c.startswith(\"next_activity_\")]\n",
    "\n",
    "    X = df_model[feature_columns]\n",
    "    y = df_model[target_columns]\n",
    "\n",
    "    print(\"Feature matrix shape:\", X.shape)\n",
    "    print(\"Target matrix shape:\", y.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(\"Random Forest training completed.\")\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1score = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return accuracy, f1score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d593eef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (64093, 1288)\n",
      "Target matrix shape: (64093, 4)\n",
      "Random Forest training completed.\n",
      "\n",
      "Accuracy: 0.6556673687495125\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      7721\n",
      "           1       0.76      0.47      0.58      2862\n",
      "           2       0.57      0.22      0.32      2236\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.70      0.66      0.68     12819\n",
      "   macro avg       0.51      0.39      0.42     12819\n",
      "weighted avg       0.69      0.66      0.65     12819\n",
      " samples avg       0.66      0.66      0.66     12819\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gijskoppenberg/Documents/UU Jaar 4/OZP/Resource-Centric-NAP/.venv/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/gijskoppenberg/Documents/UU Jaar 4/OZP/Resource-Centric-NAP/.venv/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/gijskoppenberg/Documents/UU Jaar 4/OZP/Resource-Centric-NAP/.venv/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/gijskoppenberg/Documents/UU Jaar 4/OZP/Resource-Centric-NAP/.venv/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/gijskoppenberg/Documents/UU Jaar 4/OZP/Resource-Centric-NAP/.venv/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "rf_2013ohe_accuracy, rf_2013ohe_f1 = random_forest_pipeline(df_2013_onehot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
