{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fb7df4",
   "metadata": {},
   "source": [
    "<h2> Imports, loading event-log function and cleaning pipeline </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "819e851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import statistics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a09798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset from file path\n",
    "def import_xes(file_path):\n",
    "    log = pm4py.read_xes(file_path)\n",
    "    return pm4py.convert_to_dataframe(log)\n",
    "\n",
    "# Cleaning dataset: removing unnecessary columns, shifting to resource focus\n",
    "def clean_dataset(df):\n",
    "    df_final = df[['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp']]\n",
    "    return df_final.sort_values(by=['org:resource', 'time:timestamp'])\n",
    "\n",
    "def prefix_extraction(df, min_len=1, max_len=None):\n",
    "    \"\"\"\n",
    "    Extract prefixes per resource.\n",
    "    \"\"\"\n",
    "    resource_traces = df.groupby('org:resource')['concept:name'].apply(list)\n",
    "    all_rows = []\n",
    "\n",
    "    for resource, seq in resource_traces.items():\n",
    "        max_prefix_len = len(seq) if max_len is None else min(max_len, len(seq))\n",
    "\n",
    "        for k in range(min_len, max_prefix_len):\n",
    "            prefix = seq[:k]\n",
    "            next_act = seq[k] if k < len(seq) else None\n",
    "\n",
    "            all_rows.append({\n",
    "                'resource': resource,\n",
    "                'prefix': prefix,\n",
    "                'prefix_length': k,\n",
    "                'last_activity': prefix[-1] if len(prefix) else None,\n",
    "                'next_activity': next_act\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(all_rows)\n",
    "\n",
    "def apply_bucketing(df):\n",
    "    df = df.copy()\n",
    "    df['bucket_key'] = df.apply(\n",
    "        lambda row: (row['prefix_length'], row['last_activity']), axis=1\n",
    "    )\n",
    "    df['bucket_id'] = df['bucket_key'].apply(lambda k: abs(hash(k)) % 10_000_000)\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_dataset(file_path):\n",
    "    df = import_xes(file_path)\n",
    "    df_clean = clean_dataset(df)\n",
    "    df_prefix = prefix_extraction(df_clean)\n",
    "    df_final = apply_bucketing(df_prefix)\n",
    "    return df_final \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07556d6f",
   "metadata": {},
   "source": [
    "<h1> Loading event-logs and transforming</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9d87f",
   "metadata": {},
   "source": [
    "<h4> Loading datasets </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0e27c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gijskoppenberg/Documents/UU Jaar 4/OZP/Resource-Centric-NAP/.venv/lib/python3.14/site-packages/pm4py/utils.py:987: UserWarning: In the current version, the import/export operation uses `rustxes` by default for importing/exporting files faster. Please uninstall `rustxes` to revert the behavior.\n",
      "  warnings.warn(\"In the current version, the import/export operation uses `rustxes` by default for importing/exporting files faster. Please uninstall `rustxes` to revert the behavior.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully loaded 2013 dataset\n"
     ]
    }
   ],
   "source": [
    "df_2013 = process_dataset(\"datasets/BPI_Challenge_2013_incidents.xes\")\n",
    "print(\"Sucessfully loaded 2013 dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b95400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196a658d8ad24239a7733058d4f663ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/31509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_2017 = process_dataset(\"datasets/BPI_Challenge_2017.xes\")\n",
    "print(\"Sucessfully loaded 2017 dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac937b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = process_dataset(\"datasets/BPI_Challenge_2018.xes\")\n",
    "print(\"Sucessfully loaded 2017 dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9088884b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_2019 = process_dataset(\"datasets/BPI_Challenge_2019.xes\")\n",
    "print(\"Sucessfully loaded 2019 dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551418da",
   "metadata": {},
   "source": [
    "<h1>One-Hot Encoding the event-logs</h1>\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b687e",
   "metadata": {},
   "source": [
    "<h4> Apply One-Hot encoding function </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb7b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_one_hot_encoding(df):\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    for col in ['last_activity', 'resource', 'next_activity']:\n",
    "        dummies = pd.get_dummies(df_encoded[col], prefix=col)\n",
    "        df_encoded = pd.concat([df_encoded.drop(col, axis=1), dummies], axis=1)\n",
    "\n",
    "    df_encoded = df_encoded.drop(columns=['prefix'], errors='ignore')\n",
    "    df_encoded = df_encoded.drop(columns=['bucket_key'], errors='ignore')\n",
    "\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd6c4b",
   "metadata": {},
   "source": [
    "<h4> OHE the BPIC 2013 event-log </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4914b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013_onehot = apply_one_hot_encoding(df_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e921e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_onehot = apply_one_hot_encoding(df_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5535a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018_onehot = apply_one_hot_encoding(df_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf486f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_onehot = apply_one_hot_encoding(df_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5167474",
   "metadata": {},
   "source": [
    "<h1> Training Random Forest model on OHE event-logs </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad50b67",
   "metadata": {},
   "source": [
    "<h4> Random Forest Training Pipeline </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58fe3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_pipeline(df):\n",
    "    # Remove rows with no next activity (end of resource trace)\n",
    "    target_columns = [c for c in df.columns if c.startswith(\"next_activity_\")]\n",
    "    df_model = df[df[target_columns].sum(axis=1) > 0]\n",
    "\n",
    "    feature_columns = [\n",
    "        col for col in df_model.columns \n",
    "        if col.startswith(\"last_activity_\")\n",
    "        or col.startswith(\"resource_\")\n",
    "        or col == \"prefix_length\"\n",
    "        or col == \"bucket_id\"\n",
    "    ]\n",
    "\n",
    "    target_columns = [c for c in df_model.columns if c.startswith(\"next_activity_\")]\n",
    "\n",
    "    X = df_model[feature_columns]\n",
    "    y = df_model[target_columns]\n",
    "\n",
    "    print(\"Feature matrix shape:\", X.shape)\n",
    "    print(\"Target matrix shape:\", y.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(\"Random Forest training completed.\")\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1score = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return accuracy, f1score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_2013_ohe_accuracy, rf_2013_ohe_f1 = random_forest_pipeline(df_2013_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf183a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_2017_ohe_accuracy, rf_2017_ohe_f1 = random_forest_pipeline(df_2017_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13321810",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_2018_ohe_accuracy, rf_2018_ohe_f1 = random_forest_pipeline(df_2018_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85721169",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_2019_ohe_accuracy, rf_2019_ohe_f1 = random_forest_pipeline(df_2019_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda1b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_accuracy = statistics.mean([rf_2013_ohe_accuracy,rf_2017_ohe_accuracy,rf_2018_ohe_accuracy,rf_2019_ohe_accuracy ])\n",
    "aggregated_f1score = statistics.mean([rf_2013_ohe_f1,rf_2017_ohe_f1,rf_2018_ohe_f1,rf_2019_ohe_f1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
